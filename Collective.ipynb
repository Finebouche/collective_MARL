{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2d888a-c6df-48c0-b4f9-e0f854f32264",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project_ghent/warpdrive_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "assert torch.cuda.device_count() > 0, \"This notebook needs a GPU to run!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56dca05c-2e39-461a-99ae-520dd76df36f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/project_ghent/collective_MARL', '/project_ghent/warpdrive_env/lib/python38.zip', '/project_ghent/warpdrive_env/lib/python3.8', '/project_ghent/warpdrive_env/lib/python3.8/lib-dynload', '', '/project_ghent/warpdrive_env/lib/python3.8/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc86948-b84d-467e-a9d2-d422372d527d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/project_ghent/collective_MARL', '/project_ghent/warpdrive_env/lib/python38.zip', '/project_ghent/warpdrive_env/lib/python3.8', '/project_ghent/warpdrive_env/lib/python3.8/lib-dynload', '', '/project_ghent/warpdrive_env/lib/python3.8/site-packages', '/project_ghent/warp-drive']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "path_root = Path( '/project_ghent/warp-drive/')\n",
    "sys.path.append(str(path_root))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69506557-0774-4887-a043-c60fe9bc88a7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from warp_drive.env_wrapper import EnvWrapper\n",
    "from warp_drive.training.trainer import Trainer\n",
    "from warp_drive.utils.common import get_project_root\n",
    "\n",
    "from example_envs.tag_continuous.generate_rollout_animation import (\n",
    "    generate_tag_env_rollout_animation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae374982-1ba9-4db5-aeee-0622ac7aec11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gym.spaces import Discrete, MultiDiscrete\n",
    "from IPython.display import HTML\n",
    "import yaml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29607d4-55c0-4799-802d-1e620514d8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set logger level e.g., DEBUG, INFO, WARNING, ERROR\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3dea70-9d81-4397-b9c7-d6f05fbe029e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the run config.\n",
    "\n",
    "# Here we show an example configures\n",
    "\n",
    "CFG = \"\"\"\n",
    "# Sample YAML configuration for the tag continuous environment\n",
    "name: \"tag_continuous\"\n",
    "\n",
    "# Environment settings\n",
    "env:\n",
    "    num_preys: 50\n",
    "    num_predators: 1\n",
    "    stage_size: 30\n",
    "    episode_length: 500\n",
    "    preparation_length: 100\n",
    "    max_acceleration: 0.1\n",
    "    max_turn: 2.35  # 3*pi/4 radians\n",
    "    num_acceleration_levels: 10\n",
    "    num_turn_levels: 10\n",
    "    eating_reward_for_predator: 10.0\n",
    "    eating_penalty_for_prey: -10.0\n",
    "    edge_hit_penalty: -0.0\n",
    "    end_of_game_penalty : -1.0\n",
    "    end_of_game_reward: 1.0\n",
    "    use_full_observation: False\n",
    "    eating_distance: 0.02\n",
    "    seed: 274880\n",
    "    env_backend: \"numba\"\n",
    "\n",
    "# Trainer settings\n",
    "trainer:\n",
    "    num_envs: 400 # number of environment replicas\n",
    "    train_batch_size: 10000 # total batch size used for training per iteration (across all the environments)\n",
    "    num_episodes: 500 # number of episodes to run the training for (can be arbitrarily high)\n",
    "# Policy network settings\n",
    "policy: # list all the policies below\n",
    "    prey:\n",
    "        to_train: True # flag indicating whether the model needs to be trained\n",
    "        algorithm: \"A2C\" # algorithm used to train the policy\n",
    "        gamma: 0.98 # discount rate gamms\n",
    "        lr: 0.005 # learning rate\n",
    "        vf_loss_coeff: 1 # loss coefficient for the value function loss\n",
    "        entropy_coeff:\n",
    "        - [0, 0.5]\n",
    "        - [2000000, 0.05]\n",
    "        model: # policy model settings\n",
    "            type: \"prey_policy\" # model type\n",
    "            fc_dims: [256, 256] # dimension(s) of the fully connected layers as a list\n",
    "            model_ckpt_filepath: \"\" # filepath (used to restore a previously saved model)\n",
    "    predator:\n",
    "        to_train: True\n",
    "        algorithm: \"A2C\"\n",
    "        gamma: 0.98\n",
    "        lr: 0.002\n",
    "        vf_loss_coeff: 1\n",
    "        model:\n",
    "            type: \"predator_policy\"\n",
    "            fc_dims: [256, 256]\n",
    "            model_ckpt_filepath: \"\"\n",
    "\n",
    "# Checkpoint saving setting\n",
    "saving:\n",
    "    metrics_log_freq: 100 # how often (in iterations) to print the metrics\n",
    "    model_params_save_freq: 5000 # how often (in iterations) to save the model parameters\n",
    "    basedir: \"/tmp\" # base folder used for saving\n",
    "    name: \"collective_v0\"\n",
    "    tag: \"50preys_1predator\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "run_config = yaml.safe_load(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1092e512-dc56-4bc6-bbab-235f86ef0b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from custom_env import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcfcdb1a-cf8c-4528-9881-f14adf8f51f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pycuda': {}, 'numba': {'customenv': 'custom_env_step_numba'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from warp_drive.utils.env_registrar import EnvironmentRegistrar\n",
    "from custom_env import CustomEnv\n",
    "\n",
    "env_registrar = EnvironmentRegistrar()\n",
    "env_registrar.add_cuda_env_src_path(CustomEnv.name, \"custom_env_step_numba\", env_backend=\"numba\")\n",
    "\n",
    "env_registrar._customized_cuda_env_src_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f30a4c2-3adc-4efd-b05c-17d2fba7e18e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project_ghent/warpdrive_env/lib/python3.8/site-packages/gym/utils/seeding.py:41: DeprecationWarning: \u001b[33mWARN: Function `rng.rand(*size)` is marked as deprecated and will be removed in the future. Please use `Generator.random(size)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_manager: Setting Numba to use CUDA device 0\n"
     ]
    }
   ],
   "source": [
    "env_wrapper = EnvWrapper(\n",
    "    env_obj=CustomEnv(**run_config[\"env\"]),\n",
    "    num_envs=run_config[\"trainer\"][\"num_envs\"],\n",
    "    env_backend=\"numba\",\n",
    "    env_registrar=env_registrar\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85c7dc9c-7a8e-4db5-a55e-92c7c49288f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "from warp_drive.env_cpu_gpu_consistency_checker import EnvironmentCPUvsGPU\n",
    "\n",
    "\n",
    "env_configs = {\n",
    "    \"test1\": {\n",
    "        \"num_preys\": 4,\n",
    "        \"num_predators\": 1,\n",
    "    }\n",
    "}\n",
    "\n",
    "testing_class = EnvironmentCPUvsGPU(\n",
    "    dual_mode_env_class=CustomEnv,\n",
    "    env_configs=env_configs,\n",
    "    num_envs=2,\n",
    "    num_episodes=2,\n",
    "    env_registrar=env_registrar,\n",
    ")\n",
    "\n",
    "testing_class.test_env_reset_and_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09f26aae-eb8a-463e-ba4e-5893152657f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "policy_tag_to_agent_id_map = {\n",
    "    \"predator\": list(env_wrapper.env.predators),\n",
    "    \"prey\": list(env_wrapper.env.preys),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea77e128-653f-4314-9d55-97df4a3f7df3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_tag_to_agent_id_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/project_ghent/warp-drive/warp_drive/training/trainer.py:273\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, env_wrapper, config, policy_tag_to_agent_id_map, create_separate_placeholders_for_each_policy, obs_dim_corresponding_to_num_agents, num_devices, device_id, results_dir, verbose)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m policy \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicies:\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_timestep[policy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_policy_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# Load the model parameters (if model checkpoints are specified)\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# Note: Loading the model checkpoint may also update the current timestep!\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model_checkpoint()\n",
      "File \u001b[0;32m/project_ghent/warp-drive/warp_drive/training/trainer.py:375\u001b[0m, in \u001b[0;36mTrainer._initialize_policy_model\u001b[0;34m(self, policy)\u001b[0m\n\u001b[1;32m    366\u001b[0m     model \u001b[38;5;241m=\u001b[39m FullyConnected(\n\u001b[1;32m    367\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda_envs,\n\u001b[1;32m    368\u001b[0m         policy_model_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfc_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_dim_corresponding_to_num_agents,\n\u001b[1;32m    373\u001b[0m     )\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[policy] \u001b[38;5;241m=\u001b[39m model\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(env_wrapper, run_config, policy_tag_to_agent_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c54822-be12-4932-a31a-64eca7440353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c77256-da0b-4509-9076-66a36ce7a555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "warpdrive-env",
   "language": "python",
   "name": "warpdrive-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
