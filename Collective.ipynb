{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2d888a-c6df-48c0-b4f9-e0f854f32264",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2217c171-48ce-4b10-a135-77a635537328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently Loaded Modulefiles:\n",
      " 1) rvs/1.0(default)   2) anaconda/3/2021.11   3) cuda/11.4   4) ffmpeg/4.4  \n",
      "\n",
      "Key:\n",
      "(symbolic-version)  \n"
     ]
    }
   ],
   "source": [
    "module(\"unload\", \"cuda/11.6\")\n",
    "module(\"load\", \"cuda/11.4\")\n",
    "module(\"load\",\"ffmpeg\")\n",
    "module(\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc86948-b84d-467e-a9d2-d422372d527d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "path_root1 = Path( '/cobra/u/kkumari/warp-drive')\n",
    "path_root2 = Path( '/project_ghent/warp-drive/')\n",
    "sys.path.append(str(path_root1))\n",
    "sys.path.append(str(path_root2))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ea7f608-2e4f-4eca-86ba-bf4151d8c252",
   "metadata": {},
   "source": [
    "print(sys.path)\n",
    "assert torch.cuda.device_count() > 0, \"This notebook needs a GPU to run!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69506557-0774-4887-a043-c60fe9bc88a7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from warp_drive.env_wrapper import EnvWrapper\n",
    "from warp_drive.utils.common import get_project_root\n",
    "\n",
    "from animations import (\n",
    "    generate_tag_env_rollout_animation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae374982-1ba9-4db5-aeee-0622ac7aec11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gym.spaces import Discrete, MultiDiscrete\n",
    "from IPython.display import HTML\n",
    "import yaml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29607d4-55c0-4799-802d-1e620514d8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set logger level e.g., DEBUG, INFO, WARNING, ERROR\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3dea70-9d81-4397-b9c7-d6f05fbe029e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the run config.\n",
    "\n",
    "# Here we show an example configures\n",
    "\n",
    "CFG = \"\"\"\n",
    "# Sample YAML configuration for the tag continuous environment\n",
    "name: \"tag_continuous\"\n",
    "\n",
    "# Environment settings\n",
    "env:\n",
    "    num_preys: 50\n",
    "    num_predators: 2\n",
    "    stage_size: 30\n",
    "    episode_length: 500\n",
    "    preparation_length: 100\n",
    "    max_acceleration: 0.1\n",
    "    max_turn: 2.35  # 3*pi/4 radians\n",
    "    num_acceleration_levels: 10\n",
    "    num_turn_levels: 10\n",
    "    starving_penalty_for_predator: -1.0\n",
    "    surviving_reward_for_prey: 1.0\n",
    "    edge_hit_penalty: -0.1\n",
    "    end_of_game_penalty : -100.0\n",
    "    end_of_game_reward: 100.0\n",
    "    use_full_observation: False\n",
    "    eating_distance: 0.02\n",
    "    seed: 274880\n",
    "    env_backend: \"numba\"\n",
    "\n",
    "# Trainer settings\n",
    "trainer:\n",
    "    num_envs: 400 # number of environment replicas\n",
    "    train_batch_size: 10000 # total batch size used for training per iteration (across all the environments)\n",
    "    num_episodes: 500 # number of episodes to run the training for (can be arbitrarily high)\n",
    "# Policy network settings\n",
    "policy: # list all the policies below\n",
    "    prey:\n",
    "        to_train: True # flag indicating whether the model needs to be trained\n",
    "        algorithm: \"A2C\" # algorithm used to train the policy\n",
    "        gamma: 0.98 # discount rate gamms\n",
    "        lr: 0.005 # learning rate\n",
    "        vf_loss_coeff: 1 # loss coefficient for the value function loss\n",
    "        entropy_coeff:\n",
    "        - [0, 0.5]\n",
    "        - [2000000, 0.05]\n",
    "        model: # policy model settings\n",
    "            module_name: \"fully_connected\" # model type\n",
    "            class_name: \"FullyConnected\" # class type\n",
    "            fc_dims: [256, 256] # dimension(s) of the fully connected layers as a list\n",
    "            model_ckpt_filepath: \"\" # filepath (used to restore a previously saved model)\n",
    "    predator:\n",
    "        to_train: True\n",
    "        algorithm: \"A2C\"\n",
    "        gamma: 0.98\n",
    "        lr: 0.002\n",
    "        vf_loss_coeff: 1\n",
    "        model:\n",
    "            type: \"fully_connected\"\n",
    "            fc_dims: [256, 256]\n",
    "            model_ckpt_filepath: \"\"\n",
    "\n",
    "# Checkpoint saving setting\n",
    "saving:\n",
    "    metrics_log_freq: 100 # how often (in iterations) to print the metrics\n",
    "    model_params_save_freq: 5000 # how often (in iterations) to save the model parameters\n",
    "    basedir: \"/tmp\" # base folder used for saving\n",
    "    name: \"collective_v0\"\n",
    "    tag: \"50preys_1predator\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "run_config = yaml.safe_load(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcfcdb1a-cf8c-4528-9881-f14adf8f51f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/kkumari/.local/lib/python3.9/site-packages/gym/utils/seeding.py:41: DeprecationWarning: \u001b[33mWARN: Function `rng.rand(*size)` is marked as deprecated and will be removed in the future. Please use `Generator.random(size)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_manager: Setting Numba to use CUDA device 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2021.11/lib/python3.9/site-packages/numba/cuda/decorators.py:110: NumbaDeprecationWarning: \u001b[1mEager compilation of device functions is deprecated (this occurs when a signature is provided)\u001b[0m\n",
      "  warn(NumbaDeprecationWarning(msg))\n",
      "/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2021.11/lib/python3.9/site-packages/numba/cuda/decorators.py:110: NumbaDeprecationWarning: \u001b[1mEager compilation of device functions is deprecated (this occurs when a signature is provided)\u001b[0m\n",
      "  warn(NumbaDeprecationWarning(msg))\n",
      "/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2021.11/lib/python3.9/site-packages/numba/cuda/decorators.py:110: NumbaDeprecationWarning: \u001b[1mEager compilation of device functions is deprecated (this occurs when a signature is provided)\u001b[0m\n",
      "  warn(NumbaDeprecationWarning(msg))\n",
      "/mpcdf/soft/SLE_12/packages/x86_64/anaconda/3/2021.11/lib/python3.9/site-packages/numba/cuda/decorators.py:110: NumbaDeprecationWarning: \u001b[1mEager compilation of device functions is deprecated (this occurs when a signature is provided)\u001b[0m\n",
      "  warn(NumbaDeprecationWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "from warp_drive.utils.env_registrar import EnvironmentRegistrar\n",
    "from custom_env import CUDACustomEnv\n",
    "\n",
    "env_registrar = EnvironmentRegistrar()\n",
    "env_registrar.add_cuda_env_src_path(CUDACustomEnv.name, \"custom_env_step_numba\", env_backend=\"numba\")\n",
    "\n",
    "env_wrapper = EnvWrapper(\n",
    "    env_obj=CUDACustomEnv(**run_config[\"env\"]),\n",
    "    num_envs=run_config[\"trainer\"][\"num_envs\"],\n",
    "    env_backend=\"numba\",\n",
    "    env_registrar=env_registrar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f26aae-eb8a-463e-ba4e-5893152657f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "policy_tag_to_agent_id_map = {\n",
    "    \"predator\": list(env_wrapper.env.predators),\n",
    "    \"prey\": list(env_wrapper.env.preys),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea77e128-653f-4314-9d55-97df4a3f7df3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy module FullyConnected loaded from warp_drive.training.models.fully_connected\n",
      "Policy module FullyConnected loaded from warp_drive.training.models.fully_connected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cobra/u/kkumari/warp-drive/warp_drive/training/trainer.py:249: DeprecationWarning: Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n",
      "  random.seed(seed)\n"
     ]
    }
   ],
   "source": [
    "import warp_drive.training.trainer\n",
    "from warp_drive.training.trainer import Trainer\n",
    "from importlib import reload\n",
    "reload(warp_drive.training.trainer)\n",
    "trainer = Trainer(\n",
    "    env_wrapper=env_wrapper,\n",
    "    config=run_config,\n",
    "    policy_tag_to_agent_id_map=policy_tag_to_agent_id_map,\n",
    "    num_devices=torch.cuda.device_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cc58683-728f-4ac2-b9b4-0438896a4b56",
   "metadata": {},
   "source": [
    "anim = generate_tag_env_rollout_animation(trainer)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22c54822-be12-4932-a31a-64eca7440353",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========================================\n",
      "Device: 0\n",
      "Iterations Completed                    : 1 / 25\n",
      "========================================\n",
      "Speed performance stats\n",
      "========================================\n",
      "Mean policy eval time per iter (ms)     :     101.42\n",
      "Mean action sample time per iter (ms)   :      34.89\n",
      "Mean env. step time per iter (ms)       :     243.91\n",
      "Mean training time per iter (ms)        :     114.82\n",
      "Mean total time per iter (ms)           :     505.10\n",
      "Mean steps per sec (policy eval)        :   98600.29\n",
      "Mean steps per sec (action sample)      :  286597.33\n",
      "Mean steps per sec (env. step)          :   40998.37\n",
      "Mean steps per sec (training time)      :   87091.58\n",
      "Mean steps per sec (total)              :   19798.26\n",
      "========================================\n",
      "Metrics for policy 'prey'\n",
      "========================================\n",
      "VF loss coefficient                     :    1.00000\n",
      "Entropy coefficient                     :    0.50000\n",
      "Total loss                              : 1769.81458\n",
      "Policy loss                             :   89.86565\n",
      "Value function loss                     : 1682.34534\n",
      "Mean rewards                            :    2.34585\n",
      "Max. rewards                            :  101.00000\n",
      "Min. rewards                            :   -0.10000\n",
      "Mean value function                     :    0.05163\n",
      "Mean advantages                         :   18.74980\n",
      "Mean (norm.) advantages                 :   18.74980\n",
      "Mean (discounted) returns               :   18.80143\n",
      "Mean normalized returns                 :   18.80143\n",
      "Mean entropy                            :    4.79280\n",
      "Variance explained by the value function:   -0.00002\n",
      "Std. of action_0 over agents            :    3.09713\n",
      "Std. of action_0 over envs              :    3.10261\n",
      "Std. of action_0 over time              :    3.09047\n",
      "Std. of action_1 over agents            :    3.14959\n",
      "Std. of action_1 over envs              :    3.15606\n",
      "Std. of action_1 over time              :    3.14322\n",
      "Current timestep                        : 10000.00000\n",
      "Gradient norm                           :    0.00000\n",
      "Learning rate                           :    0.00500\n",
      "Mean episodic reward                    : 3380.23163\n",
      "========================================\n",
      "Metrics for policy 'predator'\n",
      "========================================\n",
      "VF loss coefficient                     :    1.00000\n",
      "Entropy coefficient                     :    0.05000\n",
      "Total loss                              : 1619.87024\n",
      "Policy loss                             : -116.94656\n",
      "Value function loss                     : 1737.05640\n",
      "Mean rewards                            :   -2.99000\n",
      "Max. rewards                            :   -1.00000\n",
      "Min. rewards                            : -101.00000\n",
      "Mean value function                     :    0.02680\n",
      "Mean advantages                         :  -24.40131\n",
      "Mean (norm.) advantages                 :  -24.40131\n",
      "Mean (discounted) returns               :  -24.37451\n",
      "Mean normalized returns                 :  -24.37451\n",
      "Mean entropy                            :    4.79258\n",
      "Variance explained by the value function:    0.00012\n",
      "Std. of action_0 over agents            :    2.56892\n",
      "Std. of action_0 over envs              :    3.13693\n",
      "Std. of action_0 over time              :    3.12515\n",
      "Std. of action_1 over agents            :    2.59119\n",
      "Std. of action_1 over envs              :    3.17413\n",
      "Std. of action_1 over time              :    3.16269\n",
      "Current timestep                        : 10000.00000\n",
      "Gradient norm                           :    0.00000\n",
      "Learning rate                           :    0.00200\n",
      "Mean episodic reward                    : -132.38617\n",
      "======================================== \n",
      "\n",
      "[Device 0]: Saving the results to the file '/tmp/collective_v0/50preys_1predator/1679305014/results.json' \n",
      "[Device 0]: Saving the 'prey' torch model to the file: '/tmp/collective_v0/50preys_1predator/1679305014/prey_10000.state_dict'. \n",
      "[Device 0]: Saving the 'predator' torch model to the file: '/tmp/collective_v0/50preys_1predator/1679305014/predator_10000.state_dict'. \n",
      "\n",
      "\n",
      "========================================\n",
      "Device: 0\n",
      "Iterations Completed                    : 25 / 25\n",
      "========================================\n",
      "Speed performance stats\n",
      "========================================\n",
      "Mean policy eval time per iter (ms)     :      95.16\n",
      "Mean action sample time per iter (ms)   :      34.00\n",
      "Mean env. step time per iter (ms)       :     214.36\n",
      "Mean training time per iter (ms)        :     106.79\n",
      "Mean total time per iter (ms)           :     455.63\n",
      "Mean steps per sec (policy eval)        :  105084.02\n",
      "Mean steps per sec (action sample)      :  294112.54\n",
      "Mean steps per sec (env. step)          :   46650.37\n",
      "Mean steps per sec (training time)      :   93639.94\n",
      "Mean steps per sec (total)              :   21947.62\n",
      "========================================\n",
      "Metrics for policy 'prey'\n",
      "========================================\n",
      "VF loss coefficient                     :    1.00000\n",
      "Entropy coefficient                     :    0.44600\n",
      "Total loss                              :  816.02264\n",
      "Policy loss                             :    5.08110\n",
      "Value function loss                     :  812.86188\n",
      "Mean rewards                            :    0.46316\n",
      "Max. rewards                            :  101.00000\n",
      "Min. rewards                            : -100.10000\n",
      "Mean value function                     :    7.29670\n",
      "Mean advantages                         :    1.30282\n",
      "Mean (norm.) advantages                 :    1.30282\n",
      "Mean (discounted) returns               :    8.59953\n",
      "Mean normalized returns                 :    8.59953\n",
      "Mean entropy                            :    4.30572\n",
      "Variance explained by the value function:    0.02104\n",
      "Std. of action_0 over agents            :    3.43749\n",
      "Std. of action_0 over envs              :    3.42690\n",
      "Std. of action_0 over time              :    3.41339\n",
      "Std. of action_1 over agents            :    2.78923\n",
      "Std. of action_1 over envs              :    2.79275\n",
      "Std. of action_1 over time              :    2.78051\n",
      "Current timestep                        : 250000.00000\n",
      "Gradient norm                           :    0.73908\n",
      "Learning rate                           :    0.00500\n",
      "Mean episodic reward                    : 2865.08434\n",
      "========================================\n",
      "Metrics for policy 'predator'\n",
      "========================================\n",
      "VF loss coefficient                     :    1.00000\n",
      "Entropy coefficient                     :    0.05000\n",
      "Total loss                              : 1079.33899\n",
      "Policy loss                             :    4.37619\n",
      "Value function loss                     : 1074.98376\n",
      "Mean rewards                            :   -1.36000\n",
      "Max. rewards                            :   99.00000\n",
      "Min. rewards                            : -101.00000\n",
      "Mean value function                     :  -70.98575\n",
      "Mean advantages                         :   10.34431\n",
      "Mean (norm.) advantages                 :   10.34431\n",
      "Mean (discounted) returns               :  -60.64145\n",
      "Mean normalized returns                 :  -60.64145\n",
      "Mean entropy                            :    0.42113\n",
      "Variance explained by the value function:   -0.00430\n",
      "Std. of action_0 over agents            :    0.51081\n",
      "Std. of action_0 over envs              :    1.05987\n",
      "Std. of action_0 over time              :    1.01825\n",
      "Std. of action_1 over agents            :    0.00000\n",
      "Std. of action_1 over envs              :    0.00000\n",
      "Std. of action_1 over time              :    0.00000\n",
      "Current timestep                        : 250000.00000\n",
      "Gradient norm                           :    0.67710\n",
      "Learning rate                           :    0.00200\n",
      "Mean episodic reward                    : -263.80032\n",
      "======================================== \n",
      "\n",
      "[Device 0]: Saving the results to the file '/tmp/collective_v0/50preys_1predator/1679305014/results.json' \n",
      "[Device 0]: Saving the 'prey' torch model to the file: '/tmp/collective_v0/50preys_1predator/1679305014/prey_250000.state_dict'. \n",
      "[Device 0]: Saving the 'predator' torch model to the file: '/tmp/collective_v0/50preys_1predator/1679305014/predator_250000.state_dict'. \n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77c77256-da0b-4509-9076-66a36ce7a555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Device 0]: Loading the provided trainer model checkpoints. \n",
      "[Device 0]: Loading the 'prey' torch model from the previously saved checkpoint: '/tmp/collective_v0/50preys_1predator/1679305014/prey_250000.state_dict' \n",
      "[Device 0]: Updating the timestep for the 'prey' model to 250000. \n",
      "[Device 0]: Loading the 'predator' torch model from the previously saved checkpoint: '/tmp/collective_v0/50preys_1predator/1679305014/predator_250000.state_dict' \n",
      "[Device 0]: Updating the timestep for the 'predator' model to 250000. \n"
     ]
    }
   ],
   "source": [
    "trainer.load_model_checkpoint(\n",
    "    {\n",
    "        \"prey\": \"/tmp/collective_v0/50preys_1predator/1679305014/prey_250000.state_dict\",\n",
    "        \"predator\": \"/tmp/collective_v0/50preys_1predator/1679305014/predator_250000.state_dict\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c8f4873-c820-4bee-8dff-157e1a7a1b66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"432\" height=\"432\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAAI69tZGF0AAACoQYF//+d\n",
       "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2MyAtIEguMjY0L01QRUctNCBBVkMgY29kZWMg\n",
       "LSBDb3B5bGVmdCAyMDAzLTIwMjEgLSBodHRwOi8vd3d3LnZpZGVvbGFuLm9yZy94MjY0Lmh0bWwg\n",
       "LSBvcHRpb25zOiBjYWJhYz0xIHJlZj0zIGRlYmxvY2s9MTowOjAgYW5hbHlzZT0weDM6MHgxMTMg\n",
       "bWU9aGV4IHN1Ym1lPTcgcHN5PTEgcHN5X3JkPTEuMDA6MC4wMCBtaXhlZF9yZWY9MSBtZV9yYW5n\n",
       "ZT0xNiBjaHJvbWFfbWU9MSB0cmVsbGlzPTEgOHg4ZGN0PTEgY3FtPTAgZGVhZHpvbmU9MjEsMTEg\n",
       "ZmFzdF9wc2tpcD0xIGNocm9tYV9xcF9vZmZzZXQ9LTIgdGhyZWFkcz0xMyBsb29rYWhlYWRfdGhy\n",
       "ZWFkcz0yIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVy\n",
       "YXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9h\n",
       "ZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBr\n",
       "ZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xv\n",
       "b2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFw\n",
       "bWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAABayZYiEADP//vbsvgU1\n",
       "/Z/QlxEsxdpKcD4qpICAdzTAAAADAAB4HShe6DhKq9DAABtwAHBx3+SIb2YChh6rXhyXlCIVlfLF\n",
       "6YJBaL54UiJkbx2XgCAyRXicRisZ1GJ60bUDJH9qpyhJL5nb/KW/GTgy3fWOYCQF0eEfqJR2bJxo\n",
       "/8HZRVKCu4ev40Y1FBABK9zGs6gccyq3pQqyrKEf2J5+QZWHruzd8ZLMoFwVXZpaF/dyP/Ciro0c\n",
       "ziX56CLVRLgri8BXj84opwZMnXVQFrzD+8rIZ58hJeiUBbl5f5CEdgU3BNPg3MqJCHK5ll+8BrCX\n",
       "zNFP10Fyzgp3qN4L1BxdnJutGXXzzVcE/kdPtF2NEXe2Po/Zn8kSO5Y0EdCFK7jkkN1mWQIr3Itl\n",
       "q0b0fiRRjQcoSJWGz4ZUYdOGEBXz/ac6Vlbnli46nBbKM/8x11sBKlKxY2PT6TGy7v0Mzce2mjKP\n",
       "ws3gvloi7XFTgfMu6bf0GVCk9jVbre+UankvSgOF+Ho6DWAlltVgl9/H/eiqBaY4YczK06c0uSi3\n",
       "mrak1m/FKmUWRI8xAeYwX9HgQJSAWXFfgVS1CjKS3Ha1ivf4gYYHv0n0CKPGmGqht8rU2WbrXv9j\n",
       "ikNT6jKEPcda89CnSoBkfC3tHSpnYOciev0xZnBAIwLMTs6BT1ZOFj2OE+bPj1xu/MnLPIuoaLIV\n",
       "PN9lyAR2X3f76RqUDZtSCJwdc6Ct6+fzXImHUHfml0/SDPfPIBeiCJmymjtLwDWPjILalb8ggG5q\n",
       "MhXzXP7pKvt1G0qBsbNHU0oG227vnVAC+vZI1atn6mN4VHmOTC3rx/uq3HFbrRS+AG60LA9m7yNx\n",
       "hL7S9yz4xn88OM1ugfwqu2MgPY55FC+KIAgL2vBErmPJ8ZyD8w9mkIImcD/OZvMMxnLqmJjVkj0e\n",
       "ue6nszZEEZAqOoJMcabIUtCVLqWAQP8b1pNRNDXZBE7BFZX8pmOiwCCeAwolPUWodTakRbd4YzSL\n",
       "c2RHCyFwliO/ftZf4GfnK+K1dZZ9vlQyWC0fL8UdXX/MCPSRDk/FleCIODoZpvFFQ1TUUvHBtmMM\n",
       "/sn+rEn2cMnwDs/DbfUwj0rpOBfLRHhqu9BUqJu3L3ANyPH72mhQ7yg3n+J/8NDEeTjI17asAzjR\n",
       "L8yjEnHnDYHjNRkZz3ML2Do3uTdIPWge4TekNoHtopgkjl1w/4Kirrk3QD8ToJ5iC96TLAxTPN1Y\n",
       "DY2cy0N0Q9q7krziMDyaXZbxMdIRDF1FxpuDxN1yyxrYFcnFSqVjipdC6Nrzo8AIlfKMSAWaon+E\n",
       "O7rcV3txAYCESEBhHJoUs6iBvQK+NR/5az+mPD8tcpovwz5KK6tYGFTaXFU0VQ4Ti04klafQKX+e\n",
       "u3YmacpyOB8KAANkUq6mr3hDJW7hhANdh93PxQA1PXAHmiBAU24tAfwN2febjNWonvNMw3TzcZCJ\n",
       "YUVUMOjluxM8bDnUwc+bMNyDoqLoIHYj6reZjMTZQaHwZRpG2H1K3u3XvQ5t8RIZpphT0H9EGzqr\n",
       "avelRtp9L1+kmklG8qjxxY3sLIRimpXS9Hs2Wi7DzWMXZSxf7A1K969QDWszcKtynHqE7Xm0RZhR\n",
       "6mJVs5U7FW2/WuIUbuX/mbk8pfNL04DZ3+N3ja4mIpVnyTJFbqlO8zckO+IeFyGjf6qgg6CUttqS\n",
       "u3+nYVjWccnlAaffzgOiEBSYNUlvcWI1jzFlLQr9oPu2BjOToiTk8f4tJcifVK6M8K1fRPgAHoDV\n",
       "sX9s136wXscm8f7Q5fTZ7SvwlrMgNG0n5UOuaU+mXXLmEqN9l5AzmWb0o2QvJTJmrEMV01RNxux3\n",
       "KyGR3JaIZru3cXP/P3QcLChT/SO8AJ2f6X/nzFgBSrgDkqmsry0gQBPoTNTQgAYHKZpu08wYuELk\n",
       "Ig/VQixJyhOZMe/NIghF1WHkNUo8JhA61gzOsXVmr9gH5ymXMWL7Ts+zYAQEwehuTTemrhUeklC5\n",
       "X6hUx/IV42SQntyRPkFfvf0KkQrLLZIpKnSvIDIV2A0tR1ihkqGLiuELlsrv2uQ+V1PmTXJGyWU0\n",
       "I3kouRnmoGT0P96Wtdn8r6edWktDumNf4TybgduF54y0L0ePRS9t2fvs/30jDjISPU8oVtP40egT\n",
       "L5M0AsA400J5B+CSBEoDLlmoOsPPIagMCxQAAvQIKA2S0ff/GX1zZO5m8wKg2A3+xp8foWDy6L0T\n",
       "h5EeY0g5LJX1vNDXURz9mHhkg2tAGD1Xs5n2IPHpwLD6RzTdCCvotPanmWuhXvNdQ18yH5pS1MT4\n",
       "Ol2vFHnBOQqdUEkMPPNCX2hi+h2J8AXm2TVTjBqFYGKwMxtDrDt6k+eMjSlGiRvrkUfCasAVNvuj\n",
       "4G/c4zYzukre7F1IDrwYqDSDVLhEutIQbP54mF/N883ZiKLaSkT4RGu4rzbbg9cMjZ8Vt2xf6C6G\n",
       "GTQoCfYfb5P761rw1uXLCLyOMyA3ai8e2qjfPbAPRhXR+GHopiawjPcGQQkdcKcwJOntlA9pwmmO\n",
       "C0XHRUuPAz/4Bcn/YU9uv23gK6BEp4h6uFuYZv+vteatwKvvh8aP2FlAzHojN9Ka8KmHDAOgNGpl\n",
       "/trVWXuMqQJIyjJOPWG8/WV1yP/StGsaJxQKSFRA9V2i3ETdk3cvfOvDiLH7SZjv2HJH4icvQqg4\n",
       "ip/WT7Bed9H4j9r6T4L/NsFm6ZnBKOK0DSs///1RyX1NseyxZd2XH1T9VaKltyQTvXycDyiXkuEY\n",
       "lBoGg//GDFczzLvPt3AVDMETrtDlzkHFTgVVihmIbR2KAHvf739wRXMEPpi0e98rH0s6m14gJtPb\n",
       "4Dvh0X1tSJRTZpkPshEwyyS3xr5YxwN6VGCOJJQcx2jOHIrmqVrV6ELKLSgAluybQvpu+Db//cKR\n",
       "pKy0WOdh2fkkeDpobiTu8nwVwuEr3kHP0dZOliAVHcp/peJWnzFc+AbXprsiBoR4HARrDlPdJFm3\n",
       "ipFr96UPMo5uqqo0H5pJFnILk2SVr/F8bJAr2nZntIUgVhGdZMfZVZNtruhfXw5/736a8NFTzV+C\n",
       "ouNNipsHehknoSFu34wmjHEKfAWGBX62zNhAUcvPNpTUCEDus11H/8RAyIZo7BVcqvDRrklZzrD/\n",
       "sOnqZ/0+x9ZE0moJcTR/uknlWHoSiJnHEBaAIRol3ratTvwcro1JI9bYGmL+0+860pF8M/3GyhV9\n",
       "Ot7FnXEGx1UN0RGXInj8ENYHuKxg0J+JeqEBZ1xkrF2wXSmvI9RI+f34idlrqV9XSbohGwJ6frL9\n",
       "WcEuQ0qy4Vkg5d0opuk2JOw3uz/+WoZsywBks62VljmII8JgSz7lZQJGi8V5vJ/mCmvmOQpb7Hir\n",
       "vWEiRmp/a/WJh6AnlsClCB0eyqdO/YfOHzgQFfq/ba4a9AuXuGIPGwzbOPYUDNqMJoBPTryg3c0s\n",
       "144AKrZGbeB5KMbBiPHfHL9++eK66N9E/Yn84uIvhKQUl3eMx1F9ere6LHcbZ/aAShC0bbFcXT4C\n",
       "aweLudXcVVWN6/+0LAuqY66uGsifx3t+Oz1raGGPdm8fzBLTG92OrE4StILHYn3ue4Uem7gnljk1\n",
       "MkHzXNkA431i22kZRsZUsIJVfKWwUyfwWQjfX/itGMSAmhqv238SKr/xhKx3zmCkPpD7KvZDgec5\n",
       "JWVt2EQskAqaq46F2xBJvBnChdzpg/fJLqWusGKVNY4DHYoBlBp/vqtstX061fHZGy1O2BQNBtgy\n",
       "Iq2qWOU5QO2F3DH5veUI29vIIUIcEMu5x4wCL2qd26fzckqUMEojBV5uFuoj69KY+UE3PrZCtcIZ\n",
       "sxO4RuAdJD2U17qR9eB+gt19LHXK3VYLgSm+kb/kifcezkVfEYzBH0Jn2LMiZb/1m0x1jUd9HuLW\n",
       "xuGvsqGAyvkbyfXWzlVvyLfOeoXMKlNHOpavV1t/BsYPFOYib/2N5X/f5+Btk0U0QB04SlVVjN1O\n",
       "hAD9thOPoLJ7b6ejcAbRLLbsw0FlcMcQwC+b+IVmGPGQJa3C8rwCPLl3gNYvoMEVbnj1eDdSCl80\n",
       "sYc2XiHkD3gPfBPyxcsYmBSJ2aCRtp6WzTM4ufwAlNVSvL7YQPh1Cd4K7Z061OZw+rW9CTdfXNr8\n",
       "vhcQ5iejFrTlCWqukgd3QZXAodU0ptdWQsWhO62FIJGBkSNTNNFWkt8ZK2jau4r8wZgzDEY14jE9\n",
       "ETXe1aZ7dpRj5D6ddjn9KHNdp0piyRPnDxTaUAlLWI36JplsmoYv+pz2EUOaWJ9Oo1ediSEe5PSD\n",
       "75JjeUmB7Crgs6aAf081MovL3CoP2xitWRp4AYWEzlOVMXWv5ms0+hpXI+CETwo019IDsb+7WKPs\n",
       "o7g2SZfkDwB15KYZn2Cxm61AES2sfY+BTUwidws5pIhecM36TDtIIykI91CH+cURtiS+qvs15UsK\n",
       "NDw+c68iAKSQDG48fmVHZuW05zidSOesSgCWwEc7gaKjotxUr5MGvimKALufK6FYs/bjV9xt8fgN\n",
       "ubYW/Q0nitSsDNUSePQERgyGIennaBnfzbQLyvHu0pWFZJGVzbEOZeLiVfSp6mGy62b++8k9lRpp\n",
       "lyxbKO5ZROecNlweTDSV0kPAOIGLSPlYlaTZE3VVrajs0VPijd75IXAJfdKWYpTsxiJkkbfOWmab\n",
       "AgQ64cweQ3oRJUF54sYsWRGszd7pAxrkMZHE4lVYQJYgoEkMHrh0eyAAcX9n6Om/fd0aws6ksi4t\n",
       "QwqpKCfS7Pn279ky+ICIv/cpMccufCSbc8mSTwvgi0OZpNsTIW/45QA/yh6rs9pn26GEoCUsueI7\n",
       "ylVLMPWKR6uRp55YHGZs/DrFEGIdYVmI9+7rx6COmyuNxnG16z/fDxSJbkHoNSWZ2I60Ub5nHUxN\n",
       "q9jk32+M1hSMHdjfEosd4TlPdEyG3u4lnT6BiYObYMb/kt/lkcXVDX4i/UTPTmK3J5fI0ARiF6sQ\n",
       "oHMYVthUw0SPUTARuvMgp3MGrTCzx5PeaCuqQQiJf6VzLzEcNVeUsiIjTpiwzcoC6ic4U+Q2viDL\n",
       "6vwlfXl9G7BJujHc5gNL+DZt9M2WC8N0ILF4sXGtST4Xy8X14oTcK715sxdh8nGSLn4vxEPvuoGO\n",
       "Ckw7cgCTzADKuR7NeGjugwAphGlOLzLnYR3Ri4aenF8w4OUSsrLrv/6kcn2NHkf4p5N6h7uvuCvD\n",
       "Q43bmjY+otG8Igabg6wFRtMXOKOz2FrgYQSii3s5R/JFpp9/BwJTzQrMSOuFoMEPSIJe4u8d9o/6\n",
       "WbrGm66rY21tRBSXyMfpnAuThvH/ZOKUBM4lf8acmOCbcCqsi2y9G7v+QtWKUolUxptW97QjfR9x\n",
       "n8TUKGZ5UtmUPCnZ0HE80DDj6E2AcUkhsxoSrMXAdf3VDNRVZws9a4fdTjdEcvYl4bTDE9WMhvRe\n",
       "MhE7z7Ql7/4Fc5a3yzN48yTNK86etdSZidXvXAfmuvPVHMG+fhbDm0hh7PKpgrBhajT9qHk+N1pV\n",
       "miJs4oK6KxJWam0a7jtXrptchow23HQMkAwcGEmPRnNxxWMwn0baVHMzVEkBlIRTuPMKQ1dyOMQm\n",
       "sqgsb5zZ+zrXr+6/Kz2sehSMeaPNkyQhNdAbAlXWXkaNPUdu4LeLFQ5dUSszRHR61vccVoRA/ve3\n",
       "3tFXUGON0AqHFfhoWuhTqTHZbWhYmTMuz8ip94VVyGt7TyxPNmpYy8SL0/5EYt7yak2olr/3VfJZ\n",
       "l35zwI2GH1NiGKGnpwriKbg6j2oB7/8ERv5bYSxnRQFbyGVxzkysXjqY0Z2wMtwE0MD9oRB6MLFe\n",
       "gK10vzW+tzMDfHypDiaCR/pLlywGZbuZZDEnkORC5A6+bITwlk+Ebuo2X0f9iM0dzhHmO0cKWh+f\n",
       "FdGJD4k3+06sV0UzptkqC6lTsWBdksNL70+IavRazWb9mgtecnwfEpoYgvd77w2hCIGWkMV1PL9u\n",
       "ap/h9DgDiuI5jIlXQNQpWgcg6ql1AyYlrPdojqA0KbtqPTYd3DLLD1Hd6J6jimyO1sQB66MwwVVR\n",
       "L/gkUKZWnghjP+iZq0LGVTQjUvHvgV2+fuWmbGBg6o6OqRebtQLbePgF1F10KeVQlUECP89c9b78\n",
       "857PX0BaYg8TG2DV+/o+HtmjeK6dlMHRUSWO6KmddFTKnoWWUczXt33Z4VAKKwkRo1jyUWWE30id\n",
       "hkfjkOoWM+34BDAVqRUz8D9tPmHdmhCisdpLBPb6xtvgUaHkorzvJ/An8faUH/k9jlmwDxTUyf//\n",
       "HKCIbAengjTo1ql+wk91sR2TfnH7nF0XNhYf57LZPTNq3WZvaXvCkIaL0I/+G7/VpROnFUyoAFDp\n",
       "V1WrAmIqemGjS/3GOIis4p34gIB1wauMH6IhTPDWwir4hfcfXy7QDPdJFbB0r2Pv0YIazmjr+G2p\n",
       "FI3+g7BM8sbxKLZhBd958aC8EFNMfPQLHmGK90Y7oOYFgZZev6fcpqpebAbOsHWu4OAlE70lKPph\n",
       "QSDXp0Qpaeg1Okk/Wg2MlNnlEiegmyibtfpy6eeU8ZfCXtEwzt0PzTIS3VP9zrnU3tyoXOvum5c1\n",
       "3LyeccgzIpTjRiAxfZ/gQxy4pH25BsK+Fv1+qDv1MPDd9gOxKmChE/1tVf37P4fx6BLTfaXVMGOR\n",
       "KrRA+yAXNF9rfEP+cZkXbKhPYKB+/5edxjFcam3jUbW5aSAJLumjVWWbnkDDaWtUV+rtYPEV01Gs\n",
       "Lt32IYPaIrTbaOXBXkxZx8PHSIWvy/Ckll1uuKRLI8VNE76XIq52NhMogO4c3fPAkyWx9sRkMRzU\n",
       "juwTijn1CsApmo6O4dS67Vi0mEtWdicss/v0TgqbIs5sQ/VVOm12l0gijTIF/SmUUwSjAd6smPJ0\n",
       "3YA2sjT3ZS/epL2E+Y5H07Gcn5FsCfCSAajI+6OSfIcoKq1y/fTy54jOkVphUCMg41LNkkJCxlQo\n",
       "CVQu9CZjJrdldrwlNIp2OIX3R+98b6grHje5C0iNQjbZCrtTuv/nNmu///7lWRKdmsUMjcQGZLtq\n",
       "hKy/2VjYDb3JhSXrDzGFvJA+Q8bpiSYd1mEUnKXJ6eCAInvBVvOrg5t3a+1SPXkTJ8V8YkkUr2MY\n",
       "FaTit5ZnFhBbdlWgOYAT/fxqPwkM43uBLCWx8GFJubs6PWVXYD8ABf386TSUzwayPpAyE0SnDnmO\n",
       "EekxPKzd9oshdK5MfTeSbFvf0YMPC21D+MNiJbkgizyzzWJ1IPD1JIjXgIgF9xtVSrdde0CiLXz6\n",
       "tWQjTRTdigpNlXlUr3se5UfD3xaJiED+RhJccvm57VJLLeDzbzVhmlBeKVOIFyGEr8JtCYEvtjS9\n",
       "iAgAUofhWz/vv8GfUofSFh+KHH9kCnpHmEb0QZUabtLO9l9Lqm0+1fkNFxVXKmLz/FsJ1Js40tme\n",
       "kGVoqvoAAPGuvwky+hsuoFG/mKaVSsj9Mj+MLTLbqhFIENt5WA+0htn5teTqL9xHfidcrXTO4BnC\n",
       "URH9jqS4jh1cHXLbakAegOyC+nPGRIdDiYzR0y/Y4+ummPTBf4ntX0wtIzwrKd/nb/3EhOFX/D/u\n",
       "nV6m0GBrwB/ZKH59yqYLNv9TzRPQeHm2ayCkgMsxO5faam58+ymN3FZAwwGe6wc/fM2YA9UgRDWt\n",
       "TwZiAtWS6+JgZzq8KMs5wPY8zd+D9GFAQqjyRrXsInpF/7zhbP5N0IFX65el8pfjVDFZsHQtgWDc\n",
       "KycCjZjfxiO4cxcShJL/tSothkk+3Hjq6gSgVplTA6ygXCKgAAADATEAAACxQZokbEL//oywASBu\n",
       "uNAESGkaGcHKY4Z9oXjMCymqjKvDDH9/QCGSIIYXfG+1BSDSP3REIbaJiZvi3mfAm2JAdOdUkYuf\n",
       "fX9beaJRzxOUvzipBkdJAm5vJ1+gTVXrGxY83u86VUbDu+XWBimPu1glhpTpI5S/eUW4yoiQxfnz\n",
       "LZDdVJ05DbqPJtsZROMOObtfPwQVv7TRNoLC0vz5i3fDL+rDvNdxots83pk0Ez/hECDgAAAAZEGe\n",
       "QniEfwBdPOuABzgBLY1BMNcS43YB7QbceaNe+CcYLZM2535QRmXj65rqvV9AAvlE/jhz/zxJvuy5\n",
       "u/fwkXyKptWI6JtXFtTIt7VazCrYMmb9F6UEZxp/03VBxubtfcuwAUkAAABKAZ5hdEf/AJLAF2AB\n",
       "w4mp0yX1K+fkDHt6OeSrMdCcWVF4ubvJJ95DslLgIV2cI+56TQvAZzOllbQaX6uv1S4VeIKusFfC\n",
       "aoV0goIAAAA+AZ5jakf/AJL8Xoo0PeiIASfaa1E568lYIjxa3ifsoAy46yTeG6O1zp/86thG1X7z\n",
       "jC5Wv9izzyVNq5YpBN0AAADrQZpoSahBaJlMCF///oywASBUCjQBEx5V6BsprHrTbawtw6U1rTfo\n",
       "g/am4welA338rr6bLulCnoInVpNNctBAYccQrdAUSiiPufwSQQc5neUNu9IbNk2RafytGK4Gl6Xr\n",
       "rA1JZugRdP2UlMX2htB1/a/WeFRDy2pReEPlgQB6pNK1AfTVTTNEJpD0+do3iw37G8YwR76s0rit\n",
       "boTZIuiiTk9TbZucbzKoIa3lIti+63pTPaiYWFfzG6KbPG3oD1h13yQj0qkePISJea9JAv0wG04U\n",
       "aa8UQ0DHNEei8RM/6ACae31B9w4ir3obMQAAAFdBnoZFESwj/wBc51axABGIDJceOEEfR2AZsNS4\n",
       "y10nOOjgDr0bNyCXmUoI/vRaUXAuVPcLOBmpfU8/pzUEoL4ZZBtRTsmX51lsgmkibGMnbW5g2Fv8\n",
       "GNEAAABFAZ6ldEf/AJK9r2ABxPM7ydvt/CCn+MrNMsdhFR1z1cGkVeCru+xffZI7WRlcPCQqGS19\n",
       "qsEXHM9Wtm+NNZFHlr3LgCmhAAAAVgGep2pH/wCSj0VsUAHD5W5w5Ev1tcdn81/bAkqApsD7DN74\n",
       "9jAURanfTU6UWXuJFBwcd6pBa/0V5ypkqkWt8W1QK0CNIW5j8iq+kE1Iq+bLfZk5UAg4AAABDkGa\n",
       "rEmoQWyZTAhf//6MsAEoHuQAOPbUWvIVcxr27lxDyfiLcHY/KIQhWH928u5dXgWRx2uUgr4tgpOE\n",
       "5o9bRu6kw9mYlKHHAik69pwGZ7NFNljOrBl4BlLF7OHSSJOH/mML0LdtIr/uhY4tFkRYcikzpMkM\n",
       "E0oiN4MXJwEjIH8C9aME12sVttn3rhPbRFBtoi7CdgTP5DJ7uRBCBX89kIdFiNAfmEw4hvzwJfhV\n",
       "8IubH/tBhaBUJliLfgeraJBgqNbZe6tmR7/98a9Oo8xVj8qJvmcBf3fIIGW/ESi6lKdL1wvl6oFx\n",
       "DFyUprMkflAwtJjAzJR56L+c1ipai0u7GPG4NszSWCx4kse3b74pOAAAAGZBnspFFSwj/wBfibc1\n",
       "QA3TPl/ieqp+7fgtYCNtvYQ8IlAh5Jgpv8E3t9SuNofeXQqIprpxqz4e+jP2k0GASKkvpE2CzGCU\n",
       "Zqyt8R+LFYRJU//ZOovS/RYKPcLx8f5uNnQL3BUAxYEAAABXAZ7pdEf/AJcLf93QkTyBJXDoAVgE\n",
       "IHmlWDiRbT9uxUuSarmB3zTRPJ0iskH949ClFNVGey4AGqmCw1VddgHmozhLTFiHmSavkx/ZrOeC\n",
       "vluYhGxywAtoAAAARgGe62pH/wCRkpg368UijMJ7ABLVZLv6Y68EnXaG2Tw9zA57JLmpRESbINKZ\n",
       "w8u49vnGRg1HSgMPymvueDBfcxkSDJfYDRgAAADmQZrwSahBbJlMCFf//jhABFUHiQBW/HKIePSl\n",
       "w6TNNCAFQl55jq/uCBXpZEAL+6szsPl3EIbCPdmw2AhlGEnsPP4GHekEwLBnIzR5EdFh2SCH8YAj\n",
       "wYpgfzV6qE1IP/lE0f+0qL8EEW+iUFZd44Gl70Ql/wzZh69i76z1VUzEFtLOE2zARUkXkgBuH3V6\n",
       "UwEAKWalFlfR0E+EQLrIwYjqpy8um8jVaNqfU6jqMpSGRWh3DHwC5vt3QEDx2ol8rA8GBnVNh8Vt\n",
       "QCmGyGJH77rYDjuhb7OzuKi+dUMHHlWwNlnEuSVbIb0AAABnQZ8ORRUsI/8AW/D+9AYALZ0jiYsB\n",
       "Phsh07Y68nvI76Qun1XKV90sxreGGgvGnN40P5oCQydWlFw+zng9qBjJrQPouk/r3TaXuh7sE3K+\n",
       "sGEi8UfgLItacxLBw9sTGI4NgNsa04AZUQAAAEkBny10R/8Aknyeh6u4IG4ALiGW6zeV78ZTSFLX\n",
       "vV21hr/15B/7+WkS5+LUk9joZdn79zeBDffCMC1wcjpEdBv6tyCQHyhVAFlBAAAAQAGfL2pH/wCS\n",
       "UWhuQHXDxEAIzCdY0GgXEmpaYOQRzIDfksQu07fXAhTwvUCBUyNHTUHRshq22AWtEjm8mkrIGzAA\n",
       "AAC0QZs0SahBbJlMCEf//eEAEU/a8ALdTf1Ffi3VnP64eHllrB+uLl2aRIHEzTjfG7vLc79jcbsn\n",
       "yCg8ddRo6tQ2KYaIKzzgVN2nhG+pxUvMw2YIuEiBhTVy8wB5kH6ms0l/gE5M77yAjOAXr0nN+tya\n",
       "GKKDfdBM7D5d8LzSPjxFtw4KhQrkjqOBO+sN5Lz4+skEEFnsV7C53XzhfTfVZ7L1V9AzShCajyu4\n",
       "Vx/9gImEywRAWAOOAAAAYEGfUkUVLCP/AF+lz/CGPSSIaVABcVl+VVaRmlsFML1yAUUV70yL/fJa\n",
       "vSA7EksCpBCtF1PPK6RCZ5RkzRJRYU0xkjqNl5Cd/LCuJ9LqbZZThNC684paX9OWTTlSYJODAwAA\n",
       "AFoBn3F0R/8Ak1xUAHGquYFIJgiwhN8WtkIhOS9Hmb03JhKGA5GDGPZjJigQElVgD6KtjDXhnFj3\n",
       "qkjuTTTsZBt+cDWh4JMfRjW1a0ldays1u6NiDTKYK78XBLwAAABWAZ9zakf/AJJK90wkd74AFt84\n",
       "1w/Y5kP5h9shEGFtjgeFxPoBiaWey4YSuKUCOOxB/wWLZ4Lp/9uWBaYDA1q6g7BYdcC1HUQD/IlE\n",
       "kgQ1WD6AVbz+BLwAAADTQZt1SahBbJlMCP/8hABBZ5CLpwBElOPMN8h3HedhuLfDfS/Ews/+jovq\n",
       "D/abP/gkxaXut0WLyxnGEQverWkGYnsT7YSPyEWFsgNScMDBWcEtKS/ie6aaKglT06X987NdLwHj\n",
       "9x74S3ZZ5H5wopaIFk+jP9Rh2ql7Cm2YtwSi//AYMVsqiuMCg6nUE0SvTq0XhZKEi2rlK+jAge9s\n",
       "iQADIyeR8nIK0lkcs0Xp7li3tg7jP6IOh/HNMU6ecyRCm+Bggbsd7j/vaaKTqq8xvvVa1wgLuQAA\n",
       "BDptb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAABuAABAAABAAAAAAAAAAAAAAAAAQAAAAAA\n",
       "AAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC\n",
       "AAADZHRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAABuAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABsAAAAbAAAAAAACRlZHRzAAAAHGVs\n",
       "c3QAAAAAAAAAAQAAAbgAAAIAAAEAAAAAAtxtZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADIAAAAW\n",
       "AFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAKHbWlu\n",
       "ZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAAB\n",
       "AAACR3N0YmwAAAC3c3RzZAAAAAAAAAABAAAAp2F2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAB\n",
       "sAGwAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAA1\n",
       "YXZjQwFkAB7/4QAYZ2QAHqzZQbDehAAAAwAEAAADAZA8WLZYAQAGaOvjyyLA/fj4AAAAABx1dWlk\n",
       "a2hA8l8kT8W6OaUbzwMj8wAAAAAAAAAYc3R0cwAAAAAAAAABAAAAFgAAAQAAAAAUc3RzcwAAAAAA\n",
       "AAABAAAAAQAAAMBjdHRzAAAAAAAAABYAAAABAAACAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAA\n",
       "AAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAA\n",
       "AQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAAB\n",
       "AAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAFgAAAAEA\n",
       "AABsc3RzegAAAAAAAAAAAAAAFgAAGVsAAAC1AAAAaAAAAE4AAABCAAAA7wAAAFsAAABJAAAAWgAA\n",
       "ARIAAABqAAAAWwAAAEoAAADqAAAAawAAAE0AAABEAAAAuAAAAGQAAABeAAAAWgAAANcAAAAUc3Rj\n",
       "bwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBs\n",
       "AAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguNzYuMTAw\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the entire episode roll-out\n",
    "anim = generate_tag_env_rollout_animation(trainer)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15c0c93a-97b6-4658-8d74-68f39d3fa36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Device 0]: Trainer exits gracefully \n"
     ]
    }
   ],
   "source": [
    "# Close the trainer to clear up the CUDA memory heap\n",
    "trainer.graceful_close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab46149d-695e-4212-9f83-03072ab097d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
